@BOOK{Smith:2023qr,
	title = {{B}ook {T}itle},
	publisher = {Publisher},
	author = {Smith, J.~M. and Jones, A.~B.},
	year = {2023},
	edition = {7th},
}

@ARTICLE{Smith:2024jd,
	author = {Jones, A.~B. and Smith, J.~M.},
	title = {{A}rticle {T}itle},
	journal = {Journal title},
	year = {2024},
	volume = {13},
	pages = {123-456},
	number = {52},
	month = {3},
	publisher = {Publisher},
	doi = {10.1038/s41586-021-03616-x},
}

% intro [1]
@misc{intel_moores_law,
  author = {Intel},
  title = {Understanding {Moore's} {Law}},
  year = {2025},
  url = {https://newsroom.intel.com/tech101/understanding-moores-law},
  note = {Accessed: 2025-05-07},
  organization = {Intel Newsroom}
}

% Methods reinhard [1]
@techreport{reinhard2002,
  author = {Reinhard, Erik and Stark, Michael and Shirley, Peter and Ferwerda, James},
  title = {Photographic Tone Reproduction for Digital Images},
  institution = {University of Utah},
  year = {2002},
  number = {UUCS-02-001},
  type = {Technical Report},
  url = {https://www-old.cs.utah.edu/docs/techreports/2002/pdf/UUCS-02-001.pdf},
  note = {Accessed: 2025-05-08}
}

% Methods reinhard [2]
@misc{chakrabarty2025,
  author = {Chakrabarty, Deepankar},
  title = {{HDR} Imaging},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/deepankarc/hdr-imaging},
}

% intro [3]
@article{artusi2021,
  author = {Wang, Lin and Yoon, Kuk-Jin},
  title = {Deep Learning for HDR Imaging: State-of-the-Art and Future Trends},
  journal = {arXiv preprint arXiv:2110.10394},
  year = {2021},
  url = {https://arxiv.org/pdf/2110.10394},
  note = {Accessed: 2025-05-08}
}

% intro [2]
@misc{pew_mobile_2025,
  author = {{Pew Research Center}},
  title = {Mobile Fact Sheet},
  year = {2024},
  url = {https://www.pewresearch.org/internet/fact-sheet/mobile/},
  note = {Accessed: 2025-05-09},
  organization = {Pew Research Center}
}

% image registration [1]
@ARTICLE{registration,
  author = {Alcantarilla, P. F. and Nuevo, J. and Bartoli, A.},
  title = {Fast explicit diffusion for accelerated features in nonlinear scale spaces.},
  year = {2013},
  url = {https://www.bmva-archive.org.uk/bmvc/2013/Papers/paper0013/paper0013.pdf},
  note = {Accessed: 2025-05-08},
  publisher = {BMVA Press},
  doi = {10.5244/C.27.13}
}

% Quantitative [1]
@ARTICLE{quant_cite,
  author={Grossberg, M.D. and Nayar, S.K.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Modeling the space of camera response functions}, 
  year={2004},
  volume={26},
  number={10},
  pages={1272-1282},
  keywords={Layout;Optical imaging;Shape measurement;Digital cameras;Constraint theory;Image databases;Photometry;Geometry;Reflectivity;Optical films;Index Terms- Radiometric response function;camera response function;calibration;real-world response curves;empirical modeling;high-dynamic range;recovery of radiometry;nonlinear response;gamma correction;photometry;sensor modeling.},
  doi={10.1109/TPAMI.2004.88}}

% conclusion [1]
@ARTICLE{conclusion_cite,
  author={Yan, Qingsen and Yang, Kangzhen and Hu, Tao and Chen, Genggeng and Dai, Kexin and Wu, Peng and Ren, Wenqi and Zhang, Yanning},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={From Dynamic to Static: Stepwisely Generate HDR Image for Ghost Removal}, 
  year={2025},
  volume={35},
  number={2},
  pages={1409-1421},
  keywords={Feature extraction;Dynamics;Motion segmentation;Image segmentation;Image reconstruction;Circuit faults;Optical flow;High dynamic range image;ghosting artifacts;multi-exposed imaging;segment anything model},
  doi={10.1109/TCSVT.2024.3467259}}


@inbook{debevec,
author = {Debevec, Paul E. and Malik, Jitendra},
title = {Recovering High Dynamic Range Radiance Maps from Photographs},
year = {2023},
isbn = {9798400708978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3596711.3596779},
abstract = {We present a method of recovering high dynamic range radiance maps from photographs taken with conventional imaging equipment. In our method, multiple photographs of the scene are taken with different amounts of exposure. Our algorithm uses these differently exposed photographs to recover the response function of the imaging process, up to factor of scale, using the assumption of reciprocity. With the known response function, the algorithm can fuse the multiple photographs into a single, high dynamic range radiance map whose pixel values are proportional to the true radiance values in the scene. We demonstrate our method on images acquired with both photochemical and digital imaging processes. We discuss how this work is applicable in many areas of computer graphics involving digitized photographs, including image-based modeling, image compositing, and image processing. Lastly, we demonstrate a few applications of having high dynamic range radiance maps, such as synthesizing realistic motion blur and simulating the response of the human visual system.},
booktitle = {Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
articleno = {67},
numpages = {10}
}

